[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Boston 311 Service Requests",
    "section": "",
    "text": "1 Introduction\nTopic: Boston 311 Service Requests\nWe chose the Boston 311 Service Requests topic because it offers a unique window into how a city addresses everyday challenges faced by its residents. From potholes to noise complaints, this data captures the pulse of Boston’s public services and the issues that matter most to its communities. By analyzing Boston 311 Service Requests dataset, we aim to uncover patterns in the types of service requests, their geographical distribution, and how efficiently they are resolved. For readers unfamiliar with 311 systems, they serve as a vital link between residents and city departments, enabling people to report non-emergency issues and request services. Exploring this data not only highlights the responsiveness of urban governance but also sheds light on potential areas for improvement in delivering public services effectively. To start, we are interested in identifying patterns related to the volume of requests, the reasons behind them, the locations they pertain to, and the departments responsible for addressing them."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nFor this project, we are using the latest Boston 311 Service Requests dataset of year 2024, which is publicly available on the Boston.gov open data portal. This dataset is maintained by the City of Boston and contains detailed records of non-emergency service requests submitted by residents through the city’s 311 system. The data includes fields such as request types, submission dates, locations, statuses, and resolution times, offering a comprehensive view of the city’s service management. The dataset is updated regularly, ensuring it reflects current trends, although the exact frequency of updates is not explicitly specified It is provided in a tabular format, accessible as a CSV file, and includes both categorical and geographic data, such as latitude, longitude, and neighborhood identifiers. One potential challenge is the presence of missing or inconsistent data, particularly in fields like “closure reason” or “submitted photo,” which will require preprocessing. I plan to import the dataset into RStudio using the read.csv function for cleaning and analysis. The dataset can be accessed from its original source at Boston 311 Service Requests with the year 2024.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\n# load packages and read in data\n\nlibrary(readr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ tibble  3.2.1     ✔ stringr 1.5.0\n✔ tidyr   1.3.1     ✔ forcats 0.5.2\n✔ purrr   1.0.1     \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\ndf <- read_csv('/Users/andyyang/desktop/EDAV/boston311.csv')\n\n\nRows: 274415 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (20): on_time, case_status, closure_reason, case_title, subject, reason...\ndbl   (6): case_enquiry_id, fire_district, city_council_district, neighborho...\nlgl   (1): submitted_photo\ndttm  (3): open_dt, sla_target_dt, closed_dt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# pivot and calculate the number of missing values per variable\nmissing_percent <- df |>\n  summarise(across(everything(), ~ mean(is.na(.)) * 100)) |>\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Variable\",\n    values_to = \"MissingPercent\"\n  ) |>\n  arrange(desc(MissingPercent))\n\n# create the bar plot\nggplot(missing_percent, aes(x = reorder(Variable, -MissingPercent), y = MissingPercent)) +\n  geom_bar(stat = \"identity\", fill = \"tomato\") +\n  theme_minimal() +\n  labs(\n    title = \"Percentage of Missing Values per Variable\",\n    x = \"Variables\",\n    y = \"Percentage of Missing Values (%)\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(hjust = 0.5),\n    axis.title.y = element_text(margin = margin(r = 10))\n  ) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", MissingPercent)), \n            angle = 45,\n            hjust = -0.1, \n            vjust = -0.5, \n            size = 2.5) +\n  ylim(0, max(missing_percent$MissingPercent) * 1.1)\n\n\n\n\n\nBy graphing the percent of null values in each column, we can see that null values make up all of the “submitted_photo” column, and most of the “closed_photo” columns. Moreover, considering that these columns just contain links to photographs taken at the scene of the 311 request, these columns will not very important to our analysis.\nAdditionally, columns such as “closure_reason”, “closed_dt”, “location_zipcode”, and “sla_target_dt” are around 20% null values. This would only potentially impact analysis related to request response times, as we have other columns such as “location” and “latitude”/“longitude” to help us understand geographical trends, and columns such as “type”, “reason”, and “subject” to help us with request categorization.\nAll of the other columns either have 0 null values, or a very small percentage (< 1.5%) of null values, indicating that the dataset is generally complete and reliable for most analyses.\n\n\nCode\n# https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html\n# install.packages(\"naniar\")\nlibrary(naniar)\n\nnaniar::vis_miss(df,warn_large_data = FALSE) +\n  labs(\n    title = \"Missing Data Heatmap\",\n    subtitle = \"Visual Representation of Missing Values in a Subset of df\"\n  )\n\n\n\n\n\nThis plot provides a more detailed visualiation of the amount ane location of missing data, and also providing information on the overall percentage of missing values overall in the legend.\nSpecifically, we can infer that missingness is not exactly uniform, meaning that there may be clusters of rows with higher concentrations of missing data. For example, in the “closed_photo” column of the plot, we can identify a few clusters where there is more/less missing data. We also get a proportion on the total amount of missing values in our dataset–8.6%, indicating that while the overall proportion of missing data is relatively low."
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\nFor this project, we are using the latest Boston 311 Service Requests dataset of year 2024, which is publicly available on the Boston.gov open data portal. This dataset is maintained by the City of Boston and contains detailed records of non-emergency service requests submitted by residents through the city’s 311 system. The data includes fields such as request types, submission dates, locations, statuses, and resolution times, offering a comprehensive view of the city’s service management. The dataset is updated regularly, ensuring it reflects current trends, although the exact frequency of updates is not explicitly specified. It is provided in a tabular format, accessible as a CSV file, and includes both categorical and geographic data, such as latitude, longitude, and neighborhood identifiers. One potential challenge is the presence of missing or inconsistent data, particularly in fields like “closure reason” or “submitted photo,” which will require preprocessing. We plan to import the dataset into RStudio using the read.csv function for cleaning and analysis. The dataset can be accessed from its original source at Boston 311 Service Requests with the year 2024. There are 274,415 total rows and 30 columns in this dataset."
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Code\n# Load packages and data\n\nlibrary(readr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ tibble  3.2.1     ✔ stringr 1.5.0\n✔ tidyr   1.3.1     ✔ forcats 0.5.2\n✔ purrr   1.0.1     \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(lubridate)\n\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nCode\ndf <- read_csv('/Users/andyyang/desktop/EDAV/boston311.csv')\n\n\nRows: 274415 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (20): on_time, case_status, closure_reason, case_title, subject, reason...\ndbl   (6): case_enquiry_id, fire_district, city_council_district, neighborho...\nlgl   (1): submitted_photo\ndttm  (3): open_dt, sla_target_dt, closed_dt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ndim(df) #274415 rows x 30 cols\n\n\n[1] 274415     30\n\n\nCode\nstr(df) # see dtypes\n\n\nspc_tbl_ [274,415 × 30] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ case_enquiry_id               : num [1:274415] 1.01e+11 1.01e+11 1.01e+11 1.01e+11 1.01e+11 ...\n $ open_dt                       : POSIXct[1:274415], format: \"2024-01-03 09:58:13\" \"2024-01-01 01:09:00\" ...\n $ sla_target_dt                 : POSIXct[1:274415], format: \"2024-01-04 09:58:15\" NA ...\n $ closed_dt                     : POSIXct[1:274415], format: \"2024-01-03 22:59:11\" \"2024-01-17 02:51:46\" ...\n $ on_time                       : chr [1:274415] \"ONTIME\" \"ONTIME\" \"ONTIME\" \"ONTIME\" ...\n $ case_status                   : chr [1:274415] \"Closed\" \"Closed\" \"Closed\" \"Closed\" ...\n $ closure_reason                : chr [1:274415] \"Case Closed. Closed date : Thu Jan 04 03:59:11 EST 2024 Resolved\" \"Case Closed Case Noted\" \"Case Closed. Closed date : Tue Jan 02 01:22:36 EST 2024 Noted Cited for overloaded barrels and improper storage\"| __truncated__ \"Case Closed. Closed date : Mon Jan 01 17:59:25 EST 2024 Resolved Crew checked pole for damage from MVA pole was\"| __truncated__ ...\n $ case_title                    : chr [1:274415] \"Requests for Street Cleaning\" \"Police: Full Notifications\" \"Poor Conditions of Property\" \"Street Light Knock Downs\" ...\n $ subject                       : chr [1:274415] \"Public Works Department\" \"Mayor's 24 Hour Hotline\" \"Public Works Department\" \"Public Works Department\" ...\n $ reason                        : chr [1:274415] \"Street Cleaning\" \"Notification\" \"Code Enforcement\" \"Street Lights\" ...\n $ type                          : chr [1:274415] \"Requests for Street Cleaning\" \"Notification\" \"Poor Conditions of Property\" \"Street Light Knock Downs\" ...\n $ queue                         : chr [1:274415] \"PWDx_District 1C: Downtown\" \"INFO09_Current Events\" \"PWDx_Code Enforcement\" \"PWDx_Street Light Knock Downs\" ...\n $ department                    : chr [1:274415] \"PWDx\" \"INFO\" \"PWDx\" \"PWDx\" ...\n $ submitted_photo               : logi [1:274415] NA NA NA NA NA NA ...\n $ closed_photo                  : chr [1:274415] NA NA \"https://spot-boston-res.cloudinary.com/image/upload/v1704176553/boston/production/xxc2arwxlvn1vtoscdcf.jpg#spot\"| __truncated__ \"https://spot-boston-res.cloudinary.com/image/upload/v1704149959/boston/production/o2clwi71vaodxfrsrrio.jpg#spot\"| __truncated__ ...\n $ location                      : chr [1:274415] \"1661 Washington St  Roxbury  MA  02118\" \"34 High St  Dorchester  MA  02122\" \"175 W Eighth St  South Boston  MA  02127\" \"1398 River St  Hyde Park  MA  02136\" ...\n $ fire_district                 : num [1:274415] 4 7 6 12 12 11 7 7 6 NA ...\n $ pwd_district                  : chr [1:274415] \"1C\" \"03\" \"05\" \"08\" ...\n $ city_council_district         : num [1:274415] 7 3 2 5 6 9 4 4 2 NA ...\n $ police_district               : chr [1:274415] \"D4\" \"C11\" \"C6\" \"E18\" ...\n $ neighborhood                  : chr [1:274415] \"Roxbury\" \"Dorchester\" \"South Boston / South Boston Waterfront\" \"Hyde Park\" ...\n $ neighborhood_services_district: num [1:274415] 6 8 5 10 12 15 8 8 5 NA ...\n $ ward                          : chr [1:274415] \"09\" \"Ward 15\" \"Ward 7\" \"Ward 18\" ...\n $ precinct                      : chr [1:274415] \"0902\" \"1504\" \"0705\" \"1819\" ...\n $ location_street_name          : chr [1:274415] \"1661 Washington St\" \"34 High St\" \"175 W Eighth St\" \"1398 River St\" ...\n $ location_zipcode              : chr [1:274415] \"02118\" \"02122\" \"02127\" \"02136\" ...\n $ latitude                      : num [1:274415] 42.3 42.3 42.3 42.3 42.3 ...\n $ longitude                     : num [1:274415] -71.1 -71.1 -71.1 -71.1 -71.2 ...\n $ geom_4326                     : chr [1:274415] \"0101000020E6100000C908B186D3C451C06B35D24A402B4540\" \"0101000020E61000004F2BFF0DEAC351C03D2AEF588A274540\" \"0101000020E610000051D170CE5DC351C0F565068CBD2A4540\" \"0101000020E6100000467D46203DC851C0AB7192747F204540\" ...\n $ source                        : chr [1:274415] \"Citizens Connect App\" \"Constituent Call\" \"Citizens Connect App\" \"Constituent Call\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   case_enquiry_id = col_double(),\n  ..   open_dt = col_datetime(format = \"\"),\n  ..   sla_target_dt = col_datetime(format = \"\"),\n  ..   closed_dt = col_datetime(format = \"\"),\n  ..   on_time = col_character(),\n  ..   case_status = col_character(),\n  ..   closure_reason = col_character(),\n  ..   case_title = col_character(),\n  ..   subject = col_character(),\n  ..   reason = col_character(),\n  ..   type = col_character(),\n  ..   queue = col_character(),\n  ..   department = col_character(),\n  ..   submitted_photo = col_logical(),\n  ..   closed_photo = col_character(),\n  ..   location = col_character(),\n  ..   fire_district = col_double(),\n  ..   pwd_district = col_character(),\n  ..   city_council_district = col_double(),\n  ..   police_district = col_character(),\n  ..   neighborhood = col_character(),\n  ..   neighborhood_services_district = col_double(),\n  ..   ward = col_character(),\n  ..   precinct = col_character(),\n  ..   location_street_name = col_character(),\n  ..   location_zipcode = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double(),\n  ..   geom_4326 = col_character(),\n  ..   source = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nCode\nhead(df)\n\n\n# A tibble: 6 × 30\n  case_enquiry_id open_dt             sla_target_dt       closed_dt          \n            <dbl> <dttm>              <dttm>              <dttm>             \n1    101005234930 2024-01-03 09:58:13 2024-01-04 09:58:15 2024-01-03 22:59:11\n2    101005231570 2024-01-01 01:09:00 NA                  2024-01-17 02:51:46\n3    101005231577 2024-01-01 01:50:07 2024-01-05 03:30:00 2024-01-01 20:22:36\n4    101005231583 2024-01-01 02:38:00 2024-01-03 03:30:00 2024-01-01 12:59:25\n5    101005231634 2024-01-01 03:56:00 2024-01-03 03:30:00 2024-01-01 05:16:09\n6    101005231642 2024-01-01 04:05:24 2024-01-03 03:30:00 2024-01-01 05:21:19\n# ℹ 26 more variables: on_time <chr>, case_status <chr>, closure_reason <chr>,\n#   case_title <chr>, subject <chr>, reason <chr>, type <chr>, queue <chr>,\n#   department <chr>, submitted_photo <lgl>, closed_photo <chr>,\n#   location <chr>, fire_district <dbl>, pwd_district <chr>,\n#   city_council_district <dbl>, police_district <chr>, neighborhood <chr>,\n#   neighborhood_services_district <dbl>, ward <chr>, precinct <chr>,\n#   location_street_name <chr>, location_zipcode <chr>, latitude <dbl>, …\n\n\n\n\nCode\n# Cleaning\n\n# From our missing value analysis, since submitted_photo and closedphoto column do not contain many non-null values, let’s drop them\ndf <- df |> select(-submitted_photo, -closed_photo)\n\n\n\n\nCode\ndf <- df |>\n  mutate(duration_hours = as.numeric(difftime(closed_dt, open_dt, units = \"hours\")),\n         log_duration = log1p(duration_hours)) # log1p handles log(1 + x) to deal with 0 values\n\n# these are LOG TRANSFORMED durations\nggplot(df, aes(x = log_duration)) +\n  geom_histogram(binwidth = 0.2, fill = \"lightblue\", color = \"black\") +\n  labs(\n    title = \"Histogram of Log-Transformed Case Durations\",\n    x = \"Log-transformed Duration (log(hours + 1))\",\n    y = \"Frequency\"\n  ) +\n  scale_x_continuous(\n    breaks = log1p(c(0.5, 2, 5, 10, 15, 50, 100)),\n    labels = c(0.5, 2, 5, 10, 15, 50, 100)\n  ) +\n  theme_minimal()\n\n\nWarning: Removed 54921 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nTrimodal, relabled with original units, see modes at 0.5, 15, and 100 hour long cases.\n\n\nCode\ndf |>\n  group_by(reason) |>\n  summarize(n = n()) |>\n  top_n(10, n) |>\n  mutate(reason = fct_reorder(reason, n)) |>\n  ggplot(aes(x = reason, y = n)) +\n  geom_col(fill = \"blue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Reasons for 311 Service Requests\",\n    x = \"Reason\",\n    y = \"Count of Requests\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nInsert analysis here\n\n\nCode\ndf$open_d <- as.Date(df$open_dt, format = \"%Y-%m-%d\") \n\n\ndf_monthly <- df |>\n  mutate(month = floor_date(open_d, \"month\")) |>\n  group_by(month) |>\n  summarize(request_count = n(), .groups = \"drop\")\n\nggplot(df_monthly, aes(x = month, y = request_count)) +\n  geom_line(color = \"blue\") +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Number of Requests by Month\",\n    x = \"Month\",\n    y = \"Number of Requests\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\nCode\ndf$day_of_week <- wday(df$open_dt, label = TRUE)\ndf$hour <- hour(df$open_dt)\n\n# Bar plot for day of week\nggplot(df, aes(x = day_of_week)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Number of Requests by Day of Week\", x = \"Day of Week\", y = \"Count\")\n\n\n\n\n\nCode\n# Bar plot for hour of day\nggplot(df, aes(x = hour)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Number of Requests by Hour of Day\", x = \"Hour\", y = \"Count\")\n\n\n\n\n\n\n\nCode\nreason_subject_count <- df %>%\n  count(subject, reason)\n\nggplot(reason_subject_count, aes(x = subject, y = n, fill = reason)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"Reasons by Subject\", x = \"Subject\", y = \"Count\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nCode\nlibrary(ggmap)\n\n\nWarning: package 'ggmap' was built under R version 4.2.3\n\n\nℹ Google's Terms of Service: <https://mapsplatform.google.com>\n  Stadia Maps' Terms of Service: <https://stadiamaps.com/terms-of-service/>\n  OpenStreetMap's Tile Usage Policy: <https://operations.osmfoundation.org/policies/tiles/>\nℹ Please cite ggmap if you use it! Use `citation(\"ggmap\")` for details.\n\n\nCode\n# Get a map of Boston (requires a Google API key or try an open source map)\n# boston_map <- get_map(location = \"Boston, MA\", zoom = 12)\n\n# Using a base map (if available):\n# ggmap(boston_map) +\n#   geom_point(data = df, aes(x = longitude, y = latitude), alpha = 0.5, color = \"red\")\n\n# If no background map, just a basic scatter:\nggplot(df, aes(x = longitude, y = latitude)) +\n  geom_point(alpha = 0.1, color = \"red\") +\n  labs(title = \"Spatial Distribution of Requests\", x = \"Longitude\", y = \"Latitude\") +\n  coord_quickmap()\n\n\nWarning: Removed 2016 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nCode\nontime_by_reason <- df %>%\n  count(reason, on_time) %>%\n  group_by(reason) %>%\n  mutate(prop = n / sum(n))\n\nggplot(ontime_by_reason, aes(x = reorder(reason, -prop), y = prop, fill = on_time)) +\n  geom_col(position = \"fill\") +\n  coord_flip() +\n  labs(title = \"On-Time Performance by Reason\", x = \"Reason\", y = \"Proportion\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nCode\ndf$day_of_week <- wday(df$open_dt, label = TRUE, week_start = 1) # Monday = 1\ndf$hour <- hour(df$open_dt)\n\nheat_data <- df %>%\n  count(day_of_week, hour)\n\nggplot(heat_data, aes(x = hour, y = day_of_week, fill = n)) +\n  geom_tile() +\n  scale_fill_viridis_c() +\n  labs(title = \"Requests by Day of Week and Hour of Day\",\n       x = \"Hour of Day\", y = \"Day of Week\", fill = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\nCode\n# install.packages(\"ggalluvial\")\nlibrary(ggalluvial)\n\nsankey_data <- df %>%\n  count(subject, reason, type)\n\nggplot(sankey_data,\n       aes(axis1 = subject, axis2 = reason, axis3 = type, y = n)) +\n  scale_x_discrete(limits = c(\"Subject\", \"Reason\", \"Type\")) +\n  geom_alluvium(aes(fill = subject), width = 1/12) +\n  geom_stratum(width = 1/12, fill = \"grey90\", color = \"grey\") +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_minimal() +\n  labs(title = \"Sankey Diagram of Requests: Subject -> Reason -> Type\")\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\n\n\n\nCode\ntop_n_reasons <- 15\ntop_n_types <- 20\n\n# Count frequencies\nreason_counts <- df %>% count(reason, sort = TRUE)\ntype_counts <- df %>% count(type, sort = TRUE)\n\n# Identify the top reasons and types\ntop_reasons <- reason_counts$reason[1:top_n_reasons]\ntop_types <- type_counts$type[1:top_n_types]\n\n# Recode reasons and types that are not in the top lists as \"Other\"\ndf_reduced <- df %>%\n  mutate(reason = ifelse(reason %in% top_reasons, reason, \"Other\"),\n         type = ifelse(type %in% top_types, type, \"Other\"))\n\n# Now, create a summarized data frame for the alluvial plot\nalluvial_data <- df_reduced %>%\n  count(subject, reason, type)\n\n# Verify if your data is alluvial-compatible\n# The data needs to reflect the structure of flows between levels.\n# In ggalluvial, each row represents a combination of flows.\nis_alluvia_form(alluvial_data, axes = 1:3, silent = TRUE) \n\n\n[1] TRUE\n\n\nCode\n# This should return TRUE if properly structured.\n\n# Plot the alluvial diagram\n# axis1 = subject, axis2 = reason, axis3 = type\nggplot(alluvial_data,\n       aes(axis1 = subject, axis2 = reason, axis3 = type, y = n)) +\n  # The geom_alluvium and geom_stratum functions require the data to be in alluvial form\n  geom_alluvium(aes(fill = subject), width = 1/12, alpha = 0.8) +\n  geom_stratum(width = 1/12, fill = \"grey90\", color = \"grey\") +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 3) +\n  scale_x_discrete(limits = c(\"Subject\", \"Reason\", \"Type\"), expand = c(.05, .05)) +\n  labs(title = \"Alluvial Diagram of Requests: Subject -> Reason -> Type (Aggregated)\",\n       x = \"\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes."
  },
  {
    "objectID": "results.html#number-of-requests-by-season-months-days-of-the-week-and-hours-of-the-day-line-heatmap",
    "href": "results.html#number-of-requests-by-season-months-days-of-the-week-and-hours-of-the-day-line-heatmap",
    "title": "3  Results",
    "section": "3.1 Number of requests by season, months, days of the week, and hours of the day (line, heatmap)",
    "text": "3.1 Number of requests by season, months, days of the week, and hours of the day (line, heatmap)\nWe begin our analysis by investigating any seasonal trends in the number of 311 requests made.\n\n\nCode\ndf$open_d <- as.Date(df$open_dt, format = \"%Y-%m-%d\") \n\n\ndf_monthly <- df |>\n  mutate(month = floor_date(open_d, \"month\")) |>\n  group_by(month) |>\n  summarize(request_count = n(), .groups = \"drop\")\n\nggplot(df_monthly, aes(x = month, y = request_count)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"blue\", size = 2) +           # Added points\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Number of Requests by Month\",\n    x = \"Month\",\n    y = \"Number of Requests\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\nSince this dataset was pulled in November, we will assume the data for that month is incomplete. Nonetheless, the data shows a steady increase in the number of requests throughout 2024, peaking in August before declining. Perhaps this trend can be attributed to the warm weather. Warmer months, especially in summer, often bring increased outdoor activities such as public events, festivals, and tourism. These activities lead to a rise in noise complaints, trash collection requests, and reports of public infrastructure issues, explaining the upward trend in 311 requests as the weather gets warmer.\nWhile exploring seasonal trends provide us with insights into how external factors like weather and activities influence the volume of requests, we can also analyze patterns by day of the week and hour of the day to get a closer look at when residents are most likely to engage with the 311 system. These finer temporal trends can help us understand the daily rhythms of service requests and how they align with the city’s operational dynamics.\n\n\nCode\ndf$day_of_week <- wday(df$open_dt, label = TRUE, week_start = 1) # Monday = 1\ndf$hour <- hour(df$open_dt)\n\ndf$day_of_week <- factor(df$day_of_week, levels = c(\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"))\ndf$day_of_week <- fct_rev(df$day_of_week)\n\n# Then proceed with your plotting code\nheat_data <- df %>%\n  count(day_of_week, hour)\n\nggplot(heat_data, aes(x = hour, y = day_of_week, fill = n)) +\n  geom_tile() +\n  scale_fill_viridis_c() +\n  labs(title = \"Requests by Day of Week and Hour of Day\",\n       x = \"Hour of Day\", y = \"Day of Week\", fill = \"Count\") +\n  theme_minimal()\n\n\n\n\n\nThe requests appear to be more concentrated during early mornings of weekdays, suggesting that most issues reported are likely related to workweek activities, such as commuting, public services, or business-related issues. The lower activity on weekends might reflect reduced reporting due to fewer operational hours of city departments or residents being less engaged with city services during days off. The gradual decline in requests after the morning hours suggests that residents are less likely to report issues as the day progresses, possibly due to being occupied with work or other activities.\nUnderstanding when residents engage with the 311 system provides valuable insight into the timing of service needs. However, to gain a deeper understanding of the issues themselves, we can analyze the reasons behind these requests."
  },
  {
    "objectID": "results.html#exploration-of-request-reasons-bar",
    "href": "results.html#exploration-of-request-reasons-bar",
    "title": "3  Results",
    "section": "3.2 Exploration of request reasons (bar)",
    "text": "3.2 Exploration of request reasons (bar)\n\n\nCode\ndf |>\n  group_by(reason) |>\n  summarize(n = n()) |>\n  mutate(reason = fct_reorder(reason, n)) |>\n  ggplot(aes(x = reason, y = n)) +\n  geom_col(fill = \"blue\") +\n  coord_flip() +\n  labs(\n    title = \"Reasons for 311 Service Requests\",\n    x = \"Reason\",\n    y = \"Count of Requests\"\n  ) +\n  theme_minimal()+\n  theme(\n    axis.text.y = element_text(size = 8)\n  )\n\n\n\n\n\nTo gain a high-level overview, we plotted the counts for all 45 distinct reasons for requests in our dataset. The most common reason is “Enforcement & Abandoned Vehicles,” accounting for over 60,000 requests (22.5% of the total), followed by “Street Cleaning” and “Code Enforcement.”\nThis naturally leads to the question: what do these reasons actually represent? Specifically, can we uncover more details about what these requests entail? By consulting the attached data dictionary, we learn that the “reason” and “type” columns are part of a hierarchical case classification system, where “reason” represents a broader category, and “type” provides a more detailed breakdown (REASON > TYPE).\nThis allows us to create the following alluvial diagram, showing how a “reason” flows to different “types”.\n\n\nCode\ntop_5_reasons <- df %>%\n  count(reason, sort = TRUE) %>%\n  slice_max(n = 5, order_by = n) %>%\n  pull(reason)\n\n# Filter the dataset to only include these top 5 reasons\ndf_top5 <- df %>%\n  filter(reason %in% top_5_reasons)\n\ntop_10_types <- df_top5 %>%\n  count(type, sort = TRUE) %>%\n  slice_max(n = 10, order_by = n) %>%\n  pull(type)\n\ndf_aggregated <- df_top5 %>%\n  mutate(type = ifelse(type %in% top_10_types, type, \"Other\"))\n\nreason_type_counts <- df_aggregated %>%\n  count(reason, type)\n\n# Then plot as before\nggplot(reason_type_counts,\n       aes(axis1 = reason, axis2 = type, y = n)) +\n  geom_alluvium(aes(fill = reason), width = 1/12, alpha = 0.8) +\n  geom_stratum(width = 1/12, fill = \"grey80\", color = \"grey50\") +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 3, hjust = 0) +\n  scale_x_discrete(limits = c(\"Reason\", \"Type\"), expand = c(.1, .1)) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        panel.grid = element_blank(),\n        axis.title = element_blank()) +\n  coord_cartesian(clip = \"off\") +\n  theme(plot.margin = unit(c(0, 4.85, 0, 0), \"cm\"))+\n  labs(\n    title = \"Alluvial Diagram of Top 5 Reasons with Aggregated Types\",\n    fill = \"Reason\"\n  )\n\n\n\n\n\nNote that since the “type” column contains too many categories and makes the alluvial chart unreadable, we aggregated less frequent categories into an “Other” category. Specifically, this alluvial diagram only shows the top 10 most frequent types, drawn from the subsetted dataframe of top 5 reasons.\nThe main thing to notice is that the vast majority of “Enforcement & Abandoned Vehicles” requests are for Parking Enforcement (57,299 requests), making this the most common source for 311 requests in our dataset. Boston, similar to New York City, is a dense urban environment, where limited parking availability and strict enforcement policies often lead to conflicts and violations.\n“Code Enforcement” is another significant category, with the most frequent type being “Improper Storage of Trash (Barrels)” (18,782 requests), followed by “Poor Conditions of Property” (8,116 requests). The high volume of trash-related requests may stem from challenges in managing waste in densely populated areas or neighborhoods with limited access to proper waste disposal resources. We will investigate geographic trends soon.\n“Street Cleaning” requests are predominantly related to “Requests for Street Cleaning” (20,681 requests), with “CE Collection” (16,506 requests) also being a major contributor. Smaller, specialized issues like “Pick up Dead Animal” (7,854 requests) are also noteworthy.\n“Highway Maintenance” primarily involves “Request for Pothole Repair” (10,158 requests), indicating the persistent issue of potholes in the city’s infrastructure. The “Other” type here accounts for 11,083 requests, suggesting a wide range of miscellaneous highway-related issues.\n“Sanitation” requests are dominated by “Schedule a Bulk Item Pickup” (11,162 requests) and its closely related subtype “Schedule a Bulk Item Pickup SS” (6,918 requests). These reflect residents’ need for efficient disposal of larger waste items.\nNow that we have an idea of both the temporal trends of requests and the request reasons, let’s see the temporal trends of request reasons!\n\n\nCode\nselected_reasons <- c(\n                      # \"Enforcement & Abandoned Vehicles\",\n                      \"Signs & Signals\",\n                      \"Highway Maintenance\",\n                      \"Sanitation\",\n                      \"Street Cleaning\",\n                      \"Graffiti\",\n                      \"Park Maintenance & Safety\")\n\n# Filter the data to only the selected reasons\ndf_filtered <- df %>%\n  filter(reason %in% selected_reasons)\n\ndf_monthly <- df_filtered %>%\n  mutate(month = floor_date(open_dt, \"month\")) %>%\n  group_by(reason, month) %>%\n  summarize(request_count = n(), .groups = \"drop\")\n\ndf_monthly$month = as.Date(df_monthly$month, format = \"%Y-%m-%d\") \n\n# Plot the line chart\nggplot(df_monthly, aes(x = month, y = request_count, color = reason)) +\n  geom_line(size = 1) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Monthly Request Counts by Reason\",\n    x = \"Month\",\n    y = \"Number of Requests\",\n    color = \"Reason\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position=\"bottom\",\n        legend.box = \"horizontal\",\n        legend.title = element_blank(),\n\n)+\nguides(\n    color = guide_legend(\n      nrow = 2,                   # Force legend into 2 rows\n      byrow = TRUE,               # Fill the legend by row\n      # title.position = \"top\",     # Position of the title (if any)\n      title.hjust = 0.5           # Center the title horizontally\n    )\n  )\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nWe handpicked six reasons of interest and plotted them. Notably, Street Cleaning requests demonstrate a consistent upward trajectory throughout the year, culminating in a significant peak in August. Similar to before, this surge likely correlates with increased outdoor activities and public presence during the summer months, which naturally result in more debris and litter accumulation.\nSimilarly, both Sanitation and Park Maintenance & Safety categories exhibit pronounced peaks during the summer. The warmer weather encourages greater utilization of parks and recreational areas, leading to increased waste generation and a corresponding rise in maintenance and safety concerns.\nHighway Maintenance requests, on the other hand, peak in the spring. This trend is likely a result of post-winter recovery efforts, where roads suffer damage from ice, snow removal activities, and the freeze-thaw cycles common in colder climates. These conditions lead to the formation of potholes, cracks, and other roadway imperfections that require timely repairs to ensure safe and efficient transportation.\nIn contrast, the Graffiti and Signs & Signals categories maintain relatively stable request volumes throughout the year. Switching gears a bit, let’s explore how long each request takes to be resolved."
  },
  {
    "objectID": "results.html#geographic-distribution-of-requests-choropleth-bar",
    "href": "results.html#geographic-distribution-of-requests-choropleth-bar",
    "title": "3  Results",
    "section": "3.3 Geographic distribution of requests (choropleth, bar?)",
    "text": "3.3 Geographic distribution of requests (choropleth, bar?)"
  },
  {
    "objectID": "results.html#exploration-of-requests-by-department-highest-volume-of-requests-and-how-do-their-average-resolution-times-compare",
    "href": "results.html#exploration-of-requests-by-department-highest-volume-of-requests-and-how-do-their-average-resolution-times-compare",
    "title": "3  Results",
    "section": "3.4 Exploration of requests by department (highest volume of requests, and how do their average resolution times compare)",
    "text": "3.4 Exploration of requests by department (highest volume of requests, and how do their average resolution times compare)"
  },
  {
    "objectID": "results.html#dominant-subject-reason-type-paths",
    "href": "results.html#dominant-subject-reason-type-paths",
    "title": "3  Results",
    "section": "3.5 Dominant Subject-Reason-Type Paths",
    "text": "3.5 Dominant Subject-Reason-Type Paths\n\n\nCode\n# install.packages(\"ggalluvial\")\nlibrary(ggalluvial)\n\n# sankey_data <- df %>%\n#   count(subject, reason, type)\n# \n# ggplot(sankey_data,\n#        aes(axis1 = subject, axis2 = reason, axis3 = type, y = n)) +\n#   scale_x_discrete(limits = c(\"Subject\", \"Reason\", \"Type\")) +\n#   geom_alluvium(aes(fill = subject), width = 1/12) +\n#   geom_stratum(width = 1/12, fill = \"grey90\", color = \"grey\") +\n#   geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n#   theme_minimal() +\n#   labs(title = \"Sankey Diagram of Requests: Subject -> Reason -> Type\")\n\n\ntop_n_reasons <- 15\ntop_n_types <- 20\n\n# Count frequencies\nreason_counts <- df %>% count(reason, sort = TRUE)\ntype_counts <- df %>% count(type, sort = TRUE)\n\n# Identify the top reasons and types\ntop_reasons <- reason_counts$reason[1:top_n_reasons]\ntop_types <- type_counts$type[1:top_n_types]\n\n# Recode reasons and types that are not in the top lists as \"Other\"\ndf_reduced <- df %>%\n  mutate(reason = ifelse(reason %in% top_reasons, reason, \"Other\"),\n         type = ifelse(type %in% top_types, type, \"Other\"))\n\n# Now, create a summarized data frame for the alluvial plot\nalluvial_data <- df_reduced %>%\n  count(subject, reason, type)\n\n# Verify if your data is alluvial-compatible\n# The data needs to reflect the structure of flows between levels.\n# In ggalluvial, each row represents a combination of flows.\nis_alluvia_form(alluvial_data, axes = 1:3, silent = TRUE) \n\n\n[1] TRUE\n\n\nCode\n# This should return TRUE if properly structured.\n\n# Plot the alluvial diagram\n# axis1 = subject, axis2 = reason, axis3 = type\nggplot(alluvial_data,\n       aes(axis1 = subject, axis2 = reason, axis3 = type, y = n)) +\n  # The geom_alluvium and geom_stratum functions require the data to be in alluvial form\n  geom_alluvium(aes(fill = subject), width = 1/12, alpha = 0.8) +\n  geom_stratum(width = 1/12, fill = \"grey90\", color = \"grey\") +\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), size = 3) +\n  scale_x_discrete(limits = c(\"Subject\", \"Reason\", \"Type\"), expand = c(.05, .05)) +\n  labs(title = \"Alluvial Diagram of Requests: Subject -> Reason -> Type (Aggregated)\",\n       x = \"\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\nWarning in to_lodes_form(data = data, axes = axis_ind, discern =\nparams$discern): Some strata appear at multiple axes.\n\n\n\n\n\n\n\nCode\ndf <- df |>\n  mutate(duration_hours = as.numeric(difftime(closed_dt, open_dt, units = \"hours\")),\n         log_duration = log1p(duration_hours)) # log1p handles log(1 + x) to deal with 0 values\n\n# these are LOG TRANSFORMED durations\nggplot(df, aes(x = log_duration)) +\n  geom_histogram(binwidth = 0.2, fill = \"lightblue\", color = \"black\") +\n  labs(\n    title = \"Histogram of Log-Transformed Case Durations\",\n    x = \"Log-transformed Duration (log(hours + 1))\",\n    y = \"Frequency\"\n  ) +\n  scale_x_continuous(\n    breaks = log1p(c(0.5, 2, 5, 10, 15, 50, 100)),\n    labels = c(0.5, 2, 5, 10, 15, 50, 100)\n  ) +\n  theme_minimal()\n\n\nWarning: Removed 54921 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nTrimodal, relabled with original units, see modes at 0.5, 15, and 100 hour long cases.\nInsert analysis here\n\n\nCode\ndf$day_of_week <- wday(df$open_dt, label = TRUE)\ndf$hour <- hour(df$open_dt)\n\n# Bar plot for day of week\nggplot(df, aes(x = day_of_week)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Number of Requests by Day of Week\", x = \"Day of Week\", y = \"Count\")\n\n\n\n\n\nCode\n# Bar plot for hour of day\nggplot(df, aes(x = hour)) +\n  geom_bar(fill = \"steelblue\") +\n  labs(title = \"Number of Requests by Hour of Day\", x = \"Hour\", y = \"Count\")\n\n\n\n\n\n\n\nCode\nreason_subject_count <- df %>%\n  count(subject, reason)\n\nggplot(reason_subject_count, aes(x = subject, y = n, fill = reason)) +\n  geom_col() +\n  coord_flip() +\n  labs(title = \"Reasons by Subject\", x = \"Subject\", y = \"Count\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nCode\nlibrary(ggmap)\n\n\nWarning: package 'ggmap' was built under R version 4.2.3\n\n\nℹ Google's Terms of Service: <https://mapsplatform.google.com>\n  Stadia Maps' Terms of Service: <https://stadiamaps.com/terms-of-service/>\n  OpenStreetMap's Tile Usage Policy: <https://operations.osmfoundation.org/policies/tiles/>\nℹ Please cite ggmap if you use it! Use `citation(\"ggmap\")` for details.\n\n\nCode\n# Get a map of Boston (requires a Google API key or try an open source map)\n# boston_map <- get_map(location = \"Boston, MA\", zoom = 12)\n\n# Using a base map (if available):\n# ggmap(boston_map) +\n#   geom_point(data = df, aes(x = longitude, y = latitude), alpha = 0.5, color = \"red\")\n\n# If no background map, just a basic scatter:\nggplot(df, aes(x = longitude, y = latitude)) +\n  geom_point(alpha = 0.1, color = \"red\") +\n  labs(title = \"Spatial Distribution of Requests\", x = \"Longitude\", y = \"Latitude\") +\n  coord_quickmap()\n\n\nWarning: Removed 2016 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\nCode\nontime_by_reason <- df %>%\n  count(reason, on_time) %>%\n  group_by(reason) %>%\n  mutate(prop = n / sum(n))\n\nggplot(ontime_by_reason, aes(x = reorder(reason, -prop), y = prop, fill = on_time)) +\n  geom_col(position = \"fill\") +\n  coord_flip() +\n  labs(title = \"On-Time Performance by Reason\", x = \"Reason\", y = \"Proportion\") +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "results.html#resolution-times",
    "href": "results.html#resolution-times",
    "title": "3  Results",
    "section": "3.3 Resolution times",
    "text": "3.3 Resolution times\n\n\nCode\ndf <- df %>%\n  mutate(duration_hours = as.numeric(difftime(closed_dt, open_dt, units = \"hours\")),\n         log_duration = log1p(duration_hours)) \n\n\nggplot(df, aes(x = log_duration)) +\n  geom_histogram(binwidth = 0.2, fill = \"lightblue\", color = \"black\") +\n  labs(\n    title = \"Histogram of Log-Transformed Case Durations\",\n    x = \"Request Duration (Hours)\",\n    y = \"Frequency\"\n  ) +\n  scale_x_continuous(\n    breaks = log1p(c(0.5, 2, 5, 10, 15, 50, 100)),\n    labels = c(0.5, 2, 5, 10, 15, 50, 100)\n  ) +\n  theme_minimal()\n\n\nWarning: Removed 54921 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nTo analyze the duration of 311 service requests, we engineered a new feature by calculating the difference between the closed_dt and open_dt timestamps. This new column represents the time each request took from its opening to its official closure. Plotting a histogram of these raw duration values revealed a highly right-skewed distribution. This skewness indicates that while most requests were closed relatively quickly, a significant number took much longer to resolve, making for an unclear visualization.\nTo address the skewness and normalize the distribution, we applied a log-transform to the column. It’s important to note that although the data has been log-transformed to achieve a more symmetric distribution, the x-axis of the histogram is still labeled in the original time units (hours). This means that while the shape of the distribution reflects the log-transformed values, the axis maintains interpretability in terms of actual request durations.\nThe transformed distribution exhibits a tri-modal pattern, with distinct peaks at approximately 0.5 hours, 15 hours, and 100 hours. Let’s investigate further!\n\n\nCode\ndf <- df %>%\n  mutate(duration_category = case_when(\n    duration_hours < 2 ~ \"< 2 Hours\",\n    duration_hours >= 2 & duration_hours <= 24 ~ \"2-24 Hours\",\n    duration_hours > 24 ~ \"> 24 Hours\"\n  )) %>%\n  mutate(duration_category = factor(duration_category, \n                                    levels = c(\"< 2 Hours\", \"2-24 Hours\", \"> 24 Hours\")))\n\n\n\n# 2. Identify the top 5 reasons within each duration category\ntop_reasons <- df %>%\n  group_by(duration_category, reason) %>%      # Group by both category and reason\n  summarise(count = n(), .groups = 'drop') %>% # Count occurrences\n  arrange(duration_category, desc(count)) %>%  # Arrange for descending counts\n  group_by(duration_category) %>%\n  slice_max(order_by = count, n = 5) %>%       # Select top 5 per category\n  ungroup()\n\n# Optional: Ensure that 'reason' is a factor with levels ordered by count within each category\ntop_reasons <- top_reasons %>%\n  group_by(duration_category) %>%\n  mutate(reason = fct_reorder(reason, count)) %>%\n  ungroup()\n\n# 3. Create the faceted bar chart\nggplot(top_reasons, aes(x = reason, y = count, fill = reason)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +          # Create bars without legend\n  facet_wrap(~ duration_category, scales = \"free_y\", ncol=1) +        # Facet by duration category with free y-scales\n  coord_flip() +                                              # Flip coordinates for better readability\n  labs(\n    title = \"Top 5 Reasons for 311 Requests by Duration Category\",\n    x = \"Reason\",\n    y = \"Number of Requests\"\n  ) +\n  theme_minimal() +                                           # Use a minimal theme\n  theme(\n    strip.text = element_text(size = 12, face = \"bold\"),     # Style facet labels\n    axis.text = element_text(size = 10),\n    axis.title = element_text(size = 12)\n  )\n\n\n\n\n\nAfter dividing our durations into three categories (<2 hrs, 2-24 hrs, >24 hrs) and plotting the 5 most frequent reasons\nPurpose: Investigate if neighborhoods with more requests have longer resolution times\n\n\nCode\ndf |> \n  group_by(neighborhood) |> \n  summarize(avg_duration = mean(duration_hours, na.rm = TRUE), request_count = n()) |> \n  ggplot(aes(x = request_count, y = avg_duration, label = neighborhood)) +\n  geom_point(color = \"blue\", size = 3) +\n  geom_text(vjust = 1.5, hjust = 0.5, size = 3) +\n  labs(\n    title = \"Request Volume vs. Resolution Time by Neighborhood\",\n    x = \"Number of Requests\",\n    y = \"Average Resolution Time (Hours)\"\n  ) +\n  theme_minimal()\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_text()`).\n\n\n\n\n\n\n\nCode\n# List of neighborhoods to include\nselected_neighborhoods <- c(\"Allston / Brighton\", \"Roxbury\", \"Back Bay\", \"South Boston / South Boston Waterfront\", \"Downtown / Financial District\", \"Fenway / Kenmore / Audubon Circle / Longwood\", \"Hyde Park\")\n\n# Filter data for selected neighborhoods\ndf_filtered <- df |> \n  filter(neighborhood %in% selected_neighborhoods) |> \n  group_by(neighborhood) |> \n  count(reason, name = \"count\") |> \n  slice_max(order_by = count, n = 3, with_ties = FALSE) |> \n  ungroup()\n\n# Create the grouped bar chart\nggplot(df_filtered, aes(x = fct_reorder(neighborhood, count, .desc = TRUE), y = count, fill = reason)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.9), width = 0.9) +  # Grouped bar settings\n  labs(\n    title = \"Top 3 Reasons for 311 Requests by Neighborhood\",\n    x = \"Neighborhood\",\n    y = \"Count of Requests\",\n    fill = \"Reason\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 7, angle = 45, hjust = 1),  # Rotate x-axis labels for clarity\n    plot.margin = margin(10, 1, 10, 10),  # Optional: Adjust margins\n    panel.grid.major.x = element_blank()   # Optional: Remove grid lines for better readability\n  )\n\n\n\n\n\n\n\nCode\ndf |> \n  count(fire_district, police_district) |> \n  ggplot(aes(x = fire_district, y = n, fill = police_district)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Requests by Fire and Police District\", x = \"Fire District\", y = \"Count\", fill = \"Police District\") +\n  theme_minimal()\n\n\nWarning: Removed 8 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\nCode\nontime_by_reason <- df %>%\n  count(reason, on_time) %>%\n  group_by(reason) %>%\n  mutate(prop = n / sum(n))\n\nggplot(ontime_by_reason, aes(x = reorder(reason, -prop), y = prop, fill = on_time)) +\n  geom_col(position = \"fill\") +\n  coord_flip() +\n  labs(title = \"On-Time Performance by Reason\", x = \"Reason\", y = \"Proportion\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–>  –>  –>  –>  –>  –>  –>  –>  –>\n\n–>  –>  –>  –>  –>  –>  –>  –>\n\n–>\n\n–>\n\n–>\n\n–>\n\n–>  –>\n\n–>  –>  –>  –>\n\n–>  –>  –>  –>\n\n–>\n\n–>  –>  –>\n\n–>  –>  –>  –>  –>\n\n–>\n\n–>  –>  –>  –>\n\n–>  –>  –>\n\n–>  –>  –>  –>  –>\n\n–>\n\n–> ontime_by_reason <- df %>% count(reason, on_time) %>% group_by(reason) %>% mutate(prop = n / sum(n))\nggplot(ontime_by_reason, aes(x = reorder(reason, -prop), y = prop, fill = on_time)) + geom_col(position = “fill”) + coord_flip() + labs(title = “On-Time Performance by Reason”, x = “Reason”, y = “Proportion”) + theme(legend.position = “bottom”)\n\n–>"
  }
]