[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Boston 311 Service Requests",
    "section": "",
    "text": "1 Introduction\nTopic: Boston 311 Service Requests\nWe chose the Boston 311 Service Requests topic because it offers a unique window into how a city addresses everyday challenges faced by its residents. From potholes to noise complaints, this data captures the pulse of Boston’s public services and the issues that matter most to its communities. By analyzing Boston 311 Service Requests dataset, we aim to uncover patterns in the types of service requests, their geographical distribution, and how efficiently they are resolved. For readers unfamiliar with 311 systems, they serve as a vital link between residents and city departments, enabling people to report non-emergency issues and request services. Exploring this data not only highlights the responsiveness of urban governance but also sheds light on potential areas for improvement in delivering public services effectively."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nFor this project, we are using the latest Boston 311 Service Requests dataset of year 2024, which is publicly available on the Boston.gov open data portal. This dataset is maintained by the City of Boston and contains detailed records of non-emergency service requests submitted by residents through the city’s 311 system. The data includes fields such as request types, submission dates, locations, statuses, and resolution times, offering a comprehensive view of the city’s service management. The dataset is updated regularly, ensuring it reflects current trends, although the exact frequency of updates is not explicitly specified It is provided in a tabular format, accessible as a CSV file, and includes both categorical and geographic data, such as latitude, longitude, and neighborhood identifiers. One potential challenge is the presence of missing or inconsistent data, particularly in fields like “closure reason” or “submitted photo,” which will require preprocessing. I plan to import the dataset into RStudio using the read.csv function for cleaning and analysis. The dataset can be accessed from its original source at Boston 311 Service Requests with the year 2024.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\n# load packages and read in data\n\nlibrary(readr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ tibble  3.2.1     ✔ stringr 1.5.0\n✔ tidyr   1.3.1     ✔ forcats 0.5.2\n✔ purrr   1.0.1     \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\ndf <- read_csv('/Users/andyyang/desktop/EDAV/boston311.csv')\n\n\nRows: 274415 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (20): on_time, case_status, closure_reason, case_title, subject, reason...\ndbl   (6): case_enquiry_id, fire_district, city_council_district, neighborho...\nlgl   (1): submitted_photo\ndttm  (3): open_dt, sla_target_dt, closed_dt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n# pivot and calculate the number of missing values per variable\nmissing_percent <- df |>\n  summarise(across(everything(), ~ mean(is.na(.)) * 100)) |>\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Variable\",\n    values_to = \"MissingPercent\"\n  ) |>\n  arrange(desc(MissingPercent))\n\n# create the bar plot\nggplot(missing_percent, aes(x = reorder(Variable, -MissingPercent), y = MissingPercent)) +\n  geom_bar(stat = \"identity\", fill = \"tomato\") +\n  theme_minimal() +\n  labs(\n    title = \"Percentage of Missing Values per Variable\",\n    x = \"Variables\",\n    y = \"Percentage of Missing Values (%)\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(hjust = 0.5),\n    axis.title.y = element_text(margin = margin(r = 10))\n  ) +\n  geom_text(aes(label = sprintf(\"%.1f%%\", MissingPercent)), \n            angle = 45,\n            hjust = -0.1, \n            vjust = -0.5, \n            size = 2.5) +\n  ylim(0, max(missing_percent$MissingPercent) * 1.1)\n\n\n\n\n\nBy graphing the percent of null values in each column, we can see that null values make up all of the “submitted_photo” column, and most of the “closed_photo” columns. Moreover, considering that these columns just contain links to photographs taken at the scene of the 311 request, these columns will not very important to our analysis.\nAdditionally, columns such as “closure_reason”, “closed_dt”, “location_zipcode”, and “sla_target_dt” are around 20% null values. This would only potentially impact analysis related to request response times, as we have other columns such as “location” and “latitude”/“longitude” to help us understand geographical trends, and columns such as “type”, “reason”, and “subject” to help us with request categorization.\nAll of the other columns either have 0 null values, or a very small percentage (< 1.5%) of null values, indicating that the dataset is generally complete and reliable for most analyses.\n\n\nCode\n# https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html\n# install.packages(\"naniar\")\nlibrary(naniar)\n\nnaniar::vis_miss(df,warn_large_data = FALSE) +\n  labs(\n    title = \"Missing Data Heatmap\",\n    subtitle = \"Visual Representation of Missing Values in a Subset of df\"\n  )\n\n\n\n\n\nThis plot provides a more detailed visualiation of the amount ane location of missing data, and also providing information on the overall percentage of missing values overall in the legend.\nSpecifically, we can infer that missingness is not exactly uniform, meaning that there may be clusters of rows with higher concentrations of missing data. For example, in the “closed_photo” column of the plot, we can identify a few clusters where there is more/less missing data. We also get a proportion on the total amount of missing values in our dataset–8.6%, indicating that while the overall proportion of missing data is relatively low."
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\nFor this project, we are using the latest Boston 311 Service Requests dataset of year 2024, which is publicly available on the Boston.gov open data portal. This dataset is maintained by the City of Boston and contains detailed records of non-emergency service requests submitted by residents through the city’s 311 system. The data includes fields such as request types, submission dates, locations, statuses, and resolution times, offering a comprehensive view of the city’s service management. The dataset is updated regularly, ensuring it reflects current trends, although the exact frequency of updates is not explicitly specified. It is provided in a tabular format, accessible as a CSV file, and includes both categorical and geographic data, such as latitude, longitude, and neighborhood identifiers. One potential challenge is the presence of missing or inconsistent data, particularly in fields like “closure reason” or “submitted photo,” which will require preprocessing. We plan to import the dataset into RStudio using the read.csv function for cleaning and analysis. The dataset can be accessed from its original source at Boston 311 Service Requests with the year 2024. There are 274,415 total rows and 30 columns in this dataset."
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Code\n# Load packages and data\n\nlibrary(readr)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2\n──\n\n\n✔ tibble  3.2.1     ✔ stringr 1.5.0\n✔ tidyr   1.3.1     ✔ forcats 0.5.2\n✔ purrr   1.0.1     \n\n\nWarning: package 'tidyr' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(lubridate)\n\n\nLoading required package: timechange\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nCode\ndf <- read_csv('/Users/andyyang/desktop/EDAV/boston311.csv')\n\n\nRows: 274415 Columns: 30\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (20): on_time, case_status, closure_reason, case_title, subject, reason...\ndbl   (6): case_enquiry_id, fire_district, city_council_district, neighborho...\nlgl   (1): submitted_photo\ndttm  (3): open_dt, sla_target_dt, closed_dt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ndim(df) #274415 rows x 30 cols\n\n\n[1] 274415     30\n\n\nCode\nstr(df) # see dtypes\n\n\nspc_tbl_ [274,415 × 30] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ case_enquiry_id               : num [1:274415] 1.01e+11 1.01e+11 1.01e+11 1.01e+11 1.01e+11 ...\n $ open_dt                       : POSIXct[1:274415], format: \"2024-01-03 09:58:13\" \"2024-01-01 01:09:00\" ...\n $ sla_target_dt                 : POSIXct[1:274415], format: \"2024-01-04 09:58:15\" NA ...\n $ closed_dt                     : POSIXct[1:274415], format: \"2024-01-03 22:59:11\" \"2024-01-17 02:51:46\" ...\n $ on_time                       : chr [1:274415] \"ONTIME\" \"ONTIME\" \"ONTIME\" \"ONTIME\" ...\n $ case_status                   : chr [1:274415] \"Closed\" \"Closed\" \"Closed\" \"Closed\" ...\n $ closure_reason                : chr [1:274415] \"Case Closed. Closed date : Thu Jan 04 03:59:11 EST 2024 Resolved\" \"Case Closed Case Noted\" \"Case Closed. Closed date : Tue Jan 02 01:22:36 EST 2024 Noted Cited for overloaded barrels and improper storage\"| __truncated__ \"Case Closed. Closed date : Mon Jan 01 17:59:25 EST 2024 Resolved Crew checked pole for damage from MVA pole was\"| __truncated__ ...\n $ case_title                    : chr [1:274415] \"Requests for Street Cleaning\" \"Police: Full Notifications\" \"Poor Conditions of Property\" \"Street Light Knock Downs\" ...\n $ subject                       : chr [1:274415] \"Public Works Department\" \"Mayor's 24 Hour Hotline\" \"Public Works Department\" \"Public Works Department\" ...\n $ reason                        : chr [1:274415] \"Street Cleaning\" \"Notification\" \"Code Enforcement\" \"Street Lights\" ...\n $ type                          : chr [1:274415] \"Requests for Street Cleaning\" \"Notification\" \"Poor Conditions of Property\" \"Street Light Knock Downs\" ...\n $ queue                         : chr [1:274415] \"PWDx_District 1C: Downtown\" \"INFO09_Current Events\" \"PWDx_Code Enforcement\" \"PWDx_Street Light Knock Downs\" ...\n $ department                    : chr [1:274415] \"PWDx\" \"INFO\" \"PWDx\" \"PWDx\" ...\n $ submitted_photo               : logi [1:274415] NA NA NA NA NA NA ...\n $ closed_photo                  : chr [1:274415] NA NA \"https://spot-boston-res.cloudinary.com/image/upload/v1704176553/boston/production/xxc2arwxlvn1vtoscdcf.jpg#spot\"| __truncated__ \"https://spot-boston-res.cloudinary.com/image/upload/v1704149959/boston/production/o2clwi71vaodxfrsrrio.jpg#spot\"| __truncated__ ...\n $ location                      : chr [1:274415] \"1661 Washington St  Roxbury  MA  02118\" \"34 High St  Dorchester  MA  02122\" \"175 W Eighth St  South Boston  MA  02127\" \"1398 River St  Hyde Park  MA  02136\" ...\n $ fire_district                 : num [1:274415] 4 7 6 12 12 11 7 7 6 NA ...\n $ pwd_district                  : chr [1:274415] \"1C\" \"03\" \"05\" \"08\" ...\n $ city_council_district         : num [1:274415] 7 3 2 5 6 9 4 4 2 NA ...\n $ police_district               : chr [1:274415] \"D4\" \"C11\" \"C6\" \"E18\" ...\n $ neighborhood                  : chr [1:274415] \"Roxbury\" \"Dorchester\" \"South Boston / South Boston Waterfront\" \"Hyde Park\" ...\n $ neighborhood_services_district: num [1:274415] 6 8 5 10 12 15 8 8 5 NA ...\n $ ward                          : chr [1:274415] \"09\" \"Ward 15\" \"Ward 7\" \"Ward 18\" ...\n $ precinct                      : chr [1:274415] \"0902\" \"1504\" \"0705\" \"1819\" ...\n $ location_street_name          : chr [1:274415] \"1661 Washington St\" \"34 High St\" \"175 W Eighth St\" \"1398 River St\" ...\n $ location_zipcode              : chr [1:274415] \"02118\" \"02122\" \"02127\" \"02136\" ...\n $ latitude                      : num [1:274415] 42.3 42.3 42.3 42.3 42.3 ...\n $ longitude                     : num [1:274415] -71.1 -71.1 -71.1 -71.1 -71.2 ...\n $ geom_4326                     : chr [1:274415] \"0101000020E6100000C908B186D3C451C06B35D24A402B4540\" \"0101000020E61000004F2BFF0DEAC351C03D2AEF588A274540\" \"0101000020E610000051D170CE5DC351C0F565068CBD2A4540\" \"0101000020E6100000467D46203DC851C0AB7192747F204540\" ...\n $ source                        : chr [1:274415] \"Citizens Connect App\" \"Constituent Call\" \"Citizens Connect App\" \"Constituent Call\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   case_enquiry_id = col_double(),\n  ..   open_dt = col_datetime(format = \"\"),\n  ..   sla_target_dt = col_datetime(format = \"\"),\n  ..   closed_dt = col_datetime(format = \"\"),\n  ..   on_time = col_character(),\n  ..   case_status = col_character(),\n  ..   closure_reason = col_character(),\n  ..   case_title = col_character(),\n  ..   subject = col_character(),\n  ..   reason = col_character(),\n  ..   type = col_character(),\n  ..   queue = col_character(),\n  ..   department = col_character(),\n  ..   submitted_photo = col_logical(),\n  ..   closed_photo = col_character(),\n  ..   location = col_character(),\n  ..   fire_district = col_double(),\n  ..   pwd_district = col_character(),\n  ..   city_council_district = col_double(),\n  ..   police_district = col_character(),\n  ..   neighborhood = col_character(),\n  ..   neighborhood_services_district = col_double(),\n  ..   ward = col_character(),\n  ..   precinct = col_character(),\n  ..   location_street_name = col_character(),\n  ..   location_zipcode = col_character(),\n  ..   latitude = col_double(),\n  ..   longitude = col_double(),\n  ..   geom_4326 = col_character(),\n  ..   source = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nCode\nhead(df)\n\n\n# A tibble: 6 × 30\n  case_enquiry_id open_dt             sla_target_dt       closed_dt          \n            <dbl> <dttm>              <dttm>              <dttm>             \n1    101005234930 2024-01-03 09:58:13 2024-01-04 09:58:15 2024-01-03 22:59:11\n2    101005231570 2024-01-01 01:09:00 NA                  2024-01-17 02:51:46\n3    101005231577 2024-01-01 01:50:07 2024-01-05 03:30:00 2024-01-01 20:22:36\n4    101005231583 2024-01-01 02:38:00 2024-01-03 03:30:00 2024-01-01 12:59:25\n5    101005231634 2024-01-01 03:56:00 2024-01-03 03:30:00 2024-01-01 05:16:09\n6    101005231642 2024-01-01 04:05:24 2024-01-03 03:30:00 2024-01-01 05:21:19\n# ℹ 26 more variables: on_time <chr>, case_status <chr>, closure_reason <chr>,\n#   case_title <chr>, subject <chr>, reason <chr>, type <chr>, queue <chr>,\n#   department <chr>, submitted_photo <lgl>, closed_photo <chr>,\n#   location <chr>, fire_district <dbl>, pwd_district <chr>,\n#   city_council_district <dbl>, police_district <chr>, neighborhood <chr>,\n#   neighborhood_services_district <dbl>, ward <chr>, precinct <chr>,\n#   location_street_name <chr>, location_zipcode <chr>, latitude <dbl>, …\n\n\n\n\nCode\n# Cleaning\n\n# From our missing value analysis, since submitted_photo and closedphoto column do not contain many non-null values, let’s drop them\ndf <- df |> select(-submitted_photo, -closed_photo)\n\n\n\n\nCode\ndf <- df |>\n  mutate(duration_hours = as.numeric(difftime(closed_dt, open_dt, units = \"hours\")),\n         log_duration = log1p(duration_hours)) # log1p handles log(1 + x) to deal with 0 values\n\n# these are LOG TRANSFORMED durations\nggplot(df, aes(x = log_duration)) +\n  geom_histogram(binwidth = 0.2, fill = \"lightblue\", color = \"black\") +\n  labs(\n    title = \"Histogram of Log-Transformed Case Durations\",\n    x = \"Log-transformed Duration (log(hours + 1))\",\n    y = \"Frequency\"\n  ) +\n  scale_x_continuous(\n    breaks = log1p(c(0.5, 2, 5, 10, 15, 50, 100)),\n    labels = c(0.5, 2, 5, 10, 15, 50, 100)\n  ) +\n  theme_minimal()\n\n\nWarning: Removed 54921 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nTrimodal, relabled with original units, see modes at 0.5, 15, and 100 hour long cases.\n\n\nCode\ndf |>\n  group_by(reason) |>\n  summarize(n = n()) |>\n  top_n(10, n) |>\n  mutate(reason = fct_reorder(reason, n)) |>\n  ggplot(aes(x = reason, y = n)) +\n  geom_col(fill = \"blue\") +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Reasons for 311 Service Requests\",\n    x = \"Reason\",\n    y = \"Count of Requests\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nInsert analysis here\n\n\nCode\ndf$open_d <- as.Date(df$open_dt, format = \"%Y-%m-%d\") \n\n\ndf_monthly <- df |>\n  mutate(month = floor_date(open_d, \"month\")) |>\n  group_by(month) |>\n  summarize(request_count = n(), .groups = \"drop\")\n\nggplot(df_monthly, aes(x = month, y = request_count)) +\n  geom_line(color = \"blue\") +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  labs(\n    title = \"Number of Requests by Month\",\n    x = \"Month\",\n    y = \"Number of Requests\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\nAnalysis here"
  }
]